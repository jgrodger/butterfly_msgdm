---
title: "Process_butterflies"
output: html_notebook
---
# Data cleaning, obtaining site by species matrices.

### To do: add point density plots, remove Scilly Isle from basemap, consider removing exploration from this file, consider changing cutoff to 0.99 to include more Scottish and Welsh sites.

https://www.r-bloggers.com/2023/12/beautiful-maps-with-r-v-point-densities/

## Load packages.
```{r}

here::i_am("Scripts//Rmd_Scripts//Process_CSV_data.Rmd")

library(conflicted)

library(tidyverse)

library(here)

library(sgo)

library(sf)

library(tmap)

library(iNEXT)

library(segmented)

conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::select)
```

## Load data.
```{r}

# UKBMS records data extracted by David Roy on 10th March 2023
records <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_10-3-23.csv"))

# UKBMS site data extracted by David Roy on 10th March 2023 with some preprocessing using excel (see below)
sites <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_sites_10-3-23_to_correct.csv"))

#UKBMS site data provided by Rob Cooke. This includes type of survey for each site
sites.more.info <- read_csv(here("./Data/CSV_Data/ukbmsSiteLocationData1976-2019.csv"))

# UKBMS species data extracted by David Roy on 10th March 2023
species <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_species_10-3-23.csv"))

# Basemap with outlying islands
bounds <- readRDS(here("./Data./Input_Environmental_Data./gb_multipolygon_incl_ork_shet.rds"))

# Basemap without outlying islands
bounds.2 <- readRDS(here("./Data./Input_Environmental_Data./gb_multipolygon.rds"))

```

## Inspect records.
```{r}
head(records)
print("records")
nrow(records)
summary(records$YEAR)
```
## Inspect sites.
```{r}
head(sites)
nrow(sites)
```

## Clean and combine site data, rename columns in sites, species and records.
```{r}
# In the CSV, I  added in column headings and I did a sort and added in extra columns to help correct entries in incorrect columns. Some sites have incomplete info, one site remains with latitude and longitude in wrong columns and no other info, such sites are filtered in this file.

# Rename columns in sites and sites.more.info
names(sites)
sites <- sites %>%
  rename(site = SITENO,
         site.name =  SITENAME,
         gridref = GRIDREF,
         longitude = LONGITUDE,
         latitude = LATITUDE) %>% 
  #here we move values that are in the wrong columns to the correct columns
  mutate(site.name = case_when(paste2cols == 1 ~ paste(site.name, gridref, sep = "_"),
                             paste3cols == 1 ~ paste(site.name, gridref, longitude, sep = "_"),
                             .default = as.character(site.name)),
         gridref = case_when(paste2cols == 1 ~ as.character(longitude),
                             paste3cols == 1 ~ as.character(latitude),
                             .default = as.character(gridref)),
         longitude = case_when(paste2cols == 1 ~ as.numeric(latitude),
                             paste3cols == 1 ~ as.numeric(extracol1),
                             .default = as.numeric(longitude)), 
         latitude = case_when(paste2cols == 1 ~ as.numeric(extracol1),
                             paste3cols == 1 ~ as.numeric(extracol2),
                             .default = as.numeric(latitude))) %>% 
  select(-c(extracol1, extracol2, paste2cols, paste3cols))

sites.more.info <- sites.more.info %>%
  dplyr::select(-c("Site Name", "Gridreference", "Easting", "Northing","No. yrs surveyed", "First year surveyed", "Last year surveyed"))
 
names(sites.more.info) <- c("site", "length", "country", "no.sections",  "survey.type" )

# Rename columns in species 

species <- species %>% 
  rename(species.no = SPECIES, 
         common.name = COMMON_NAME,
         sci.name = SCI_NAME,
         strategy = STRATEGY,
         habitat = HABITAT)%>% 
  mutate(species.no = as.character(species.no))

#rename columns in records
records<- records %>%
  rename(site = SITE, 
        species.no = SPECIES,
        year = YEAR,
        month = MONTH, 
        day = DAY, 
        week.no = WEEKNO, 
        day.no = DAYNO, 
        count = COUNT) %>% 
  mutate(species.no = as.character(species.no))


print("rows of records")
nrow(records)

print("sites in records")
length(unique(records$site))

print("species in records")
length(unique(records$species.no))
```


# Merge site data
```{r}
# Some sites  were not in site data from Rob , they must have been filtered out from the data he used for some reason
print("number of sites before merging operation")
nrow(sites)

sites <- merge(sites, sites.more.info, by = "site", all.x = TRUE)

print("number of sites after merging operation")
nrow(sites)

names(sites)

table(sites$survey.type)
```


## Filter out zero counts to make processing quicker (note this removes info on survey effort).
```{r}
#The original dataset includes zeros where species were not observed at a site. The pivot_wider() function can reintroduce them in the site by species matrix, and meanwhile, we don't need to process them with the rest of the records. 

records <- filter(records, count !=0) #keep records where one or more butterflies of a species were seen at a site

print("rows of records")
nrow(records)

print("sites in records")
length(unique(records$site))

print("species in records")
length(unique(records$species.no))
```

## Combine records for small and essex skipper (species.nos 119 and 120), including those where observer recorded it as either of the two (species.no 200). These species cannot be reliably distinguished on the wing.
```{r}
print ("number of rows in species dataframe")
nrow(species)

#contents for new row
new.row <- c ("1000", "Combined Skippers", "Thymelicus lineola-sylvestris", "Wider countryside sp", "Grassland", 1)

species <- species  %>%
  rbind(new.row)    %>%
  filter(species.no!= 119,
         species.no!= 120, 
         species.no!= 200)

print("number of rows in species dataframe after combining skippers")
nrow(species)
```

## Recode species.no in records for the two skipper species in the records dataframe to 1000 to match species dataframe.
```{r}
records <- records %>% 
 mutate(species.no = case_match(species.no, c("119", "120", "200") ~ "1000", .default = species.no))

print("Rows of records after combining skippers ") # Check it is the same

nrow(records)

print("sites in records")
length(unique(records$site))

print("species in records") # Check it is lower
length(unique(records$species.no))
```

## Filter out records that are moths, or do not identify to species level (low taxonomic resolution) or that denote that no butterflies were seen
```{r}
# Filter species dataset to only include butterflies
species <- species %>%
  filter(include ==1)

print("rows of species after removing moths, low taxonomic resolution and no butterfles seen categories")
nrow(species)

# Filter records dataset to only include butterflies identified to species level.
records <- records %>%
  filter(species.no %in% species$species.no)

# Filter sites to exclude any that have no remaining records
sites <- sites %>% 
  filter(site %in% unique(records$site))

print("rows of sites after removing moths and low taxonomic resolution and no butterfles seen categories")
nrow(sites)

print("sites in records")
length(unique(records$site))

print("rows of records removing records of moths and low taxonomic resolution and no butterfles seen categories ")
nrow(records)

print("species in records")
length(unique(records$species.no))
```


# Remove migrants and extinct species. Two extinct species were considered extinct before records started, and so any records now are eigher migrants or from butterfly farms, so can be removed with migrants. Also remove Large Copper Lycaena dispar (species.no 66), which is classified as a habitat specialist but is only present in a few sites and years following failed reintroduction attempts (not present in 2015-2019 data anyway) 
# https://butterfly-conservation.org/butterflies/large-tortoiseshell
# https://butterfly-conservation.org/butterflies/black-veined-white
```{r}
# Filter species
table(species$strategy)

species <- species %>% 
  filter(strategy == "Wider countryside sp"| strategy == "Habitat specialist",
         species.no != 66)

table(species$strategy)

print("number of rows in species dataset")
nrow(species)

# Filter records to these species
records <- records %>%
  filter(species.no %in% species$species.no)

sites <- sites %>% 
  filter(site %in% unique(records$site))

print("After removing records ofextinct, vagrants, migrants and large copper ")

print("rows of records")
nrow(records)

print("sites in records")
length(unique(records$site))

print("species in records")
length(unique(records$species.no))

# Filter out sites that no longer have any records
sites <- sites %>% 
  filter(site %in% unique(records$site))

print("sites after removing sites not represented in records")
nrow(sites)

table(sites$survey.type)
```
## Check for sites with inadequate locality info.
```{r}
# for inspection only, sites that have no co-ordinates or grid square reference
bad.sites <- filter(sites, is.na(longitude) == T &  is.na(gridref) ==T, 
                    gridref != "Lurgan")

print("number of sites with inadequate locality info")
nrow(bad.sites)
```

# Remove sites in Ireland,  Channel Islands, Lundy, Scilly, Isle of Man from sites data.
```{r}
table(sites$country)

sites <- sites%>%
  filter(country != "Channel Isles" & country != "Isle of Man" & country != "Northern Ireland",
               site != 1791 & site != 1837)  # sites on Lundy and Scilly were identified previously

table(sites$country)

print("number of rows of sites")
nrow(sites)

records <- records %>% 
  filter(site %in% sites$site)

species <- species %>% 
  filter (species.no %in% records$species.no) #species after filtering out Ireland,  Channel Islands, Lundy, Scilly, Isle of Man"

print("rows of records")
nrow(records)


print("sites in records")
length(unique(records$site))


print("species in records")
length(unique(records$species.no))

print("number of rows in species dataframe")
nrow(species)
```

# Add eastings, northings and National Grid References to site data
```{r}
# Check if all sites have latitude
any(is.na(sites$latitude))

# Get eastings and northings
pts <- sgo_points(sites, coords = c("longitude", "latitude"), epsg=4277) #this is the epsg for long and lat
bng.pts1 <- sgo_lonlat_bng(pts)

# Get national gridref 1 km scale 
points2 <- sgo_bng_ngr(bng.pts1, digits = 4)

#put coords and ngr into a dataframe
pts.df1 <- as.data.frame(bng.pts1)
pts.df1 <- pts.df1 %>%
  mutate(ngr.1km = points2$ngr,
         ngr.1km = str_replace_all(ngr.1km, fixed(" "), ""))  %>%  #get rid of white spaces
  select(x, y, ngr.1km, site)
 
# add data to sites dataframe
print("number of sites before merging operation")
nrow(sites)
sites <- merge(sites, pts.df1, by = "site")
print("number of sites after merging operation")
nrow(sites)
```

## Plot Sites
```{r}
plot.points <- st_as_sf(sites, coords=c("x","y"), remove = FALSE, crs = 27700) 

#get a set of points for each unique grid cell

print("sites")
nrow(plot.points)

basemap <-tm_shape(bounds) +
  tm_borders()
pointsmap <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.05, col = "blue")

pointsmap2 <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.5, col = "blue")


print(pointsmap)
print(pointsmap2)
```

## Explore sampling effort and create variable to group surveys by sampling period. Divide the prescribed sampling period into 4 quarters. To have equal length quarters, the last week of March (week 0) is included in the first period and first week of October (week 40) in 4th period


```{r}
# Create columns to identify survey events and site-year combinations.
records<- records %>%
  mutate(survey.info = paste(site, year, month, day, week.no, sep = "_"),
         site.year.month = paste(site, year, month, sep = "_"),
         site.year = paste(site, year, sep = "_"))

# Check variation in sampling effort by week
table(records$week.no)
hist(records$week.no)

# Create sampling period variable
records <- mutate(records, 
                  sampling.period = case_match(week.no,
                    -7:-1 ~ "pre-april",
                    0:6   ~ "per1",
                    7:13  ~ "per2",
                    14:20 ~ "per3",
                    21:27 ~ "per4",
                    28:40 ~ "post-september"))

# Get a dataframe with the number of surveys per period in each site in each year
surveys.by.period <- records %>%
  distinct(survey.info, .keep_all = TRUE) %>%
  group_by(site, year, sampling.period) %>%
    summarise(surveys.per.period = n()) %>%
      pivot_wider(names_from = sampling.period,
        values_from = surveys.per.period,
        values_fill = 0) %>%
    mutate(site.year = paste(site, year, sep = "_"), 
         #criterion for inclusion, being sampled in all 4 periods
         all.4 = per1 > 0 & per2 > 0 & per3 > 0 & per4 > 0) %>% 
  ungroup()

# Get the site-year combinations with sampling in all 4 periods in 2015 to 2019
# and the number of well sampled years for each
surveys.by.period.all.4  <- surveys.by.period %>% 
  filter(all.4 = TRUE, 
         year %in% 2015:2019) %>% 
  group_by(site) %>%
  summarise(well.sampled.years = n())

# Check how many sites were well sampled in 1, 2 , 3, 4 or 5 years
table(surveys.by.period.all.4$well.sampled.years)

surveys.all.4 <- select(surveys.by.period, site.year, all.4)

# Subset records to those from sites sampled in all four years
records <- merge(records, surveys.all.4, by = "site.year", all.x = TRUE)

#add number of well-sampled years records
records <- merge(records, surveys.by.period.all.4, by = "site", all.x = TRUE)

check <- head(records, 100)
```


## filter records to 2015-2019 for sites with two years well sampled

```{r}
print("filter to 2015-2019")
records <- records %>% 
  filter(year %in% 2015:2019)

print("rows of records")
nrow(records)
table(sites$country)

print("sites in records")
length(unique(records$site))

print("species in records")
length(unique(records$species.no))

print("filter to sites with two well sampled years")




print("rows of records")
nrow(records)

print("sites in records")
length(unique(records$site))

print("species in records")
length(unique(records$species.no))


sites <- sites %>%
  filter(site %in% records$site)

print("number of sites")
nrow(sites)
table(sites$country)

species <- species %>%
  filter(species.no %in% records$species.no)

print("number of species")
nrow(species)


```


```{r}
# Summarise records to get records per species per site 

aggregated.records <-  records %>%
  group_by (site, species.no)  %>% 
summarise(total.records = sum(count))

print("number of rows of aggregated records")
nrow(aggregated.records)

print("number of sites")
length(unique(aggregated.records$site))

print("number of species")
length(unique(aggregated.records$species.no))
```

# Get site by species count matrix
```{r}
# Get species.no as character variable
aggregated.records$species.no <- paste("species", aggregated.records$species.no, sep = "_")

# Get a site by species dataframe with counts of observations
site.by.obs.5.year.counts <- aggregated.records %>%
  pivot_wider(names_from = species.no,
              values_from = total.records,
              values_fill = 0) %>% # for cases when there wasn't a zero count record for a species that wasn't recorded in a survey, should still be zero
  column_to_rownames(var = "site")


print("sites and species in matrix")
print("sites, species")
dim(site.by.obs.5.year.counts)

#make a presence absence site by specie matrix

site.by.obs.5.year.presabs <- site.by.obs.5.year.counts
site.by.obs.5.year.presabs[site.by.obs.5.year.presabs[, ] > 0] <- 1
```


## check coverage and filter to sites with adequate coverage
```{r}

#Transpose sity by counts matrix for use  by iNEXT package functions
check.coverage <- t(site.by.obs.5.year.counts)

#DataInfo() performs the first part of what iNEXT() does in seconds. the whole iNEXT() function would have to be left overnight for the whole dataset
#https://cran.r-project.org/web/packages/iNEXT/vignettes/Introduction.pdf

coverage <- DataInfo(check.coverage,  datatype ="abundance")

# Inspect the distribution of coverage values
hist(coverage$SC)
hist(coverage$SC, ylim = c(0, 50))
hist(coverage$SC, xlim = c(0.95, 1), breaks = 1000)
quantile(coverage$SC, seq(from = 0, to = 1, by = 0.01))


# Get a dataframe with coverage values to merge into the sites dataframe
cov.merge <- coverage %>%
  dplyr::select(Assemblage, n, S.obs, SC) 
names(cov.merge) <- c("site", "total.butterflies", "richness", "coverage")
```

# add coverage data to sites and explore coverage
```{r}
sites <- merge(sites, cov.merge, by = "site")

scotland <- filter(sites, country == "Scotland")
wales <- filter(sites, country == "Wales")
england <- filter(sites, country == "England")


hist(scotland$coverage)
hist(scotland$coverage, xlim = c(0.95, 1), breaks = 1000)
hist(wales$coverage, xlim = c(0.95, 1), breaks = 1000)
hist(england$coverage, xlim = c(0.95, 1), breaks = 1000)

# Get some descriptive statistics for sites
sum3 <- sites%>%
  group_by(survey.type) %>%
  summarise(n = n(),
            mean.richness = mean(richness),
            mean.individuals = mean(total.butterflies),
            mean.coverage = mean(coverage)
      )
sum3

```


## Explore the relationship between coverage and richness
```{r}

plot(richness~coverage, data = sites)

plot(richness~coverage, data = sites, xlim = c(0.96, 1))

# Step 1: Call the pdf command to start the plot
pdf(file = "rich+cov.pdf",  
    width = 4, # The width of the plot in inches
    height = 4) # The height of the plot in inches

plot(richness~coverage, data = sites, xlim = c(0.96, 1))


# Step 3: Run dev.off() to create the file!
dev.off()

m2 <- lm(richness~coverage, data = sites)

summary(m2)

check<- filter(sites, coverage >= 0.99)
m3 <- lm(richness~coverage, data = check)


check1<- filter(sites, coverage >= 0.9975)
m4 <- lm(richness~coverage, data = check1)

check2<- filter(sites, coverage >= 0.999)
m5 <- lm(richness~coverage, data = check1)



summary(m5)
```
# Look for a breakpoint with segmented regression. This doesn not indicate saturation, however, so does not help select the cut off.
```{r}
m5<- segmented(m2, psi = c(0.995))

summary(m5)

plot(m5)

plot(m5, xlim = c(0.95,1), res=TRUE, col=2, conf.level=.95)
```


# Filter to sites with sufficient coverage and effort. 0.999 gives an expectation that one thousand individuals would have to be observed before a new species was observed.
```{r}
print("number of sites before filtering out adequate coverage ")
nrow(sites)

table(sites$country)

sites.spatial <- sites%>% 
                filter(coverage >= 0.999)

print("minimum coverage in selected sites")
min(sites.spatial$coverage)

print("number of sites after filtering out adequate coverage and years of sampling")
nrow(sites.spatial)

#this is the one to export!
site.by.obs.5.year.presabs1 <- site.by.obs.5.year.presabs %>%
  filter(rownames(site.by.obs.5.year.presabs) %in% sites.spatial$site)

table(sites.spatial$country)

print("are there any species with no records")
any(colSums(site.by.obs.5.year.presabs1)==0)

print("are there any sites with no records")

any(rowSums(site.by.obs.5.year.presabs1)==0)

print("sites and species in matrix")
print("sites, species")
dim(site.by.obs.5.year.presabs1)
#make a presence absence site by species matrix

```

# Check how many of these were sampled in April. April surveys may be omitted quite frequently due to poor weather. setdiff() shows that 65 of the sites not sampled in April met the coverage criterion. Quite a few of these are in Scotland, and would be expected to have delayed sampling starts relative to England. I would rather keep these sites in. I think the other criteria are sufficient.
```{r}
#get 
check <- records %>%
  filter(month == 4) %>%
   distinct(site, .keep_all = TRUE)

# get sites in our filtered dataset that are not in the set of sites sampled in April
not_april <- setdiff(rownames(site.by.obs.5.year.presabs1), check$site )
not_april_sites <- filter(sites, site %in% not_april)

plot.points <- st_as_sf(not_april_sites, coords=c("x","y"), remove = FALSE, crs = 27700)#I want to keep coords in the dataframe
#
# #get a set of points for each unique grid cell
#
print("sites")
nrow(plot.points)

basemap <-tm_shape(bounds.2) +
  tm_borders()

pointsmap2 <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.5, alpha = 0.5, col = "blue")


print(pointsmap2)
```
## Plot Sites
```{r}

plot.points <- st_as_sf(sites.spatial, coords=c("x","y"), remove = FALSE, crs = 27700)

print("sites")
nrow(plot.points)

basemap <-tm_shape(bounds.2) +
  tm_borders()
pointsmap <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.05, col = "blue")

pointsmap2 <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.5, alpha = 0.5, col = "blue")

print(pointsmap)
print(pointsmap2)

pdf(file = "map_sites.pdf",
    width = 4, # The width of the plot in inches
    height = 4) # The height of the plot in inches

print(pointsmap2)


# Step 3: Run dev.off() to create the file!
dev.off()

```

# save processed data
```{r}
write_rds(site.by.obs.5.year.presabs1, file = here("./Data/Processed_Data/site_by_obs_5_year_pres_abs.rds"))

write_rds(species, file = here("./Data/Processed_Data/species_5_year.rds"))

write_rds(sites.spatial, file = here("./Data/Processed_Data/processed_5_year_sites.rds"))
```




