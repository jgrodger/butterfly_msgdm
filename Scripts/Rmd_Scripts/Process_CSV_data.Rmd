---
title: "Processing butterfly data from UKBMS"
output: html_notebook
---


This script loads ukbms data for records, sites and species. It cleans the data, 
renames columns for ease of use, filters by various criteria, including coverage 
and sampling effort, and saves data for further use, and including extracting 
environmental data from matching grid cells in butterflies_combine_env_data.Rmd.

#### Load packages.
```{r}
here::i_am("Scripts//Rmd_Scripts//Process_CSV_data.Rmd")

library(conflicted)

library(tidyverse)

library(here)

library(sgo)

library(sf)

library(tmap)

library(iNEXT)

library(tictoc)

conflicts_prefer(dplyr::filter)
conflicts_prefer(dplyr::mutate)
conflicts_prefer(dplyr::select)
```

#### Data.
```{r}
tic()
# UKBMS records data extracted by David Roy on 10th March 2023
records <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_10-3-23.csv"))

# UKBMS site data extracted by David Roy on 10th March 2023 with some preprocessing using excel (see below)
sites <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_sites_10-3-23_to_correct.csv"))

# UKBMS site data provided by Rob Cooke. This includes type of survey for each site
sites.more.info <- read_csv(here("./Data/CSV_Data/ukbmsSiteLocationData1976-2019.csv"))

# UKBMS species data extracted by David Roy on 10th March 2023
species <- read_csv(here("./Data/CSV_Data/ukbms_Rogers_species_10-3-23.csv"))

# Basemap with outlying islands
GB <- readRDS(here("./Data./Maps./gb_multipolygon_incl_ork_shet_simplified.rds"))

# Basemap without outlying islands
GB_simpl <- readRDS(here("./Data./Maps./gb_multipolygon_simplified.rds"))
```

#### Functions
```{r}
# A function to add numbers of records, species and sites at each step to a table
add_prisma <- function(tibble = prisma, recs = records, step_name = "?"){
  records <- recs
  prisma_temp <- tibble(
    "Step" = step_name,
    "Records" = nrow(records),
    "Sites in records" = length(unique(records$site)),
    "Species in records" = length(unique(records$species.no)),
    "Sites in sites" = nrow(sites),
    "Species in species" = nrow(species)) 
  new_prisma <- rbind(prisma, prisma_temp)
}

# A function for filtering data: this assumes that the environment contains objects 
# called records, sites, species as prepared above. The argument is the dataset that 
# will already have been filtered by another criterion. The other 
# two are then filtered to contain records still relevant
filter_ukbms <- function(filter_by){
  
  if(filter_by == "records") {
  species <- filter (species, species.no %in% records$species.no)   
  sites <-  filter(sites, site %in% records$site)  
  
  } else if  ((filter_by == "sites")) {
  records <- filter(records, site %in% sites$site)
  species <- filter (species, species.no %in% records$species.no) 
  
  } else if (filter_by == "species"){
  records <- filter(records, species.no %in% species$species.no)
  sites <-  filter(sites, site %in% records$site)
  }
  
  filtered_data <- list(records, sites, species)
  names(filtered_data) <- c("records", "sites", "species")
  return(filtered_data)
}
```

#### Inspect records.
```{r}
head(records)
```
#### Inspect sites.
```{r}
head(sites)
```


#### Inspect species.
```{r}
head(species)
```


#### Make a table to summarise remaining data and check data filtering at each step
```{r}
# Make a table
prisma <- tibble(
"Step" = "Imported Data",
"Records" = nrow(records),
"Sites in records" = length(unique(records$SITE)),
"Species in records" = length(unique(records$SPECIES)),
"Sites in sites" = nrow(sites),
"Species in species" = nrow(species)
)

prisma
```


#### Clean data and rename columns in sites, species and records.
```{r}
# In the original CSV, some sites had site name info spread across multiple columns, so that part of the site name was in the GRIDREF and LONGITUDE columns and data for the other columns were shifted to the right. In the edited CSV  I  added in column headings "extracol1" and "extracol2"; did a sort and added in columns called "paste2cols"  and "paste3cols" to identify rows where site name info was spread across two or three columns respectively. I uploaded the CSV with these additions and it is cleaned here.

# Some sites have incomplete info, one site remains with latitude and longitude in wrong columns and no other info. These sites are filtered on other criteria below.

# Rename columns in sites and sites.more.info
names(sites)
sites <- sites %>%
  rename(site = SITENO,
         site.name =  SITENAME,
         gridref = GRIDREF,
         longitude = LONGITUDE,
         latitude = LATITUDE) %>% 
  #here we move values that are in the wrong columns to the correct columns
  mutate(site.name = case_when(paste2cols == 1 ~ paste(site.name, gridref, sep = "_"),
                             paste3cols == 1 ~ paste(site.name, gridref, longitude, sep = "_"),
                             .default = as.character(site.name)),
         gridref = case_when(paste2cols == 1 ~ as.character(longitude),
                             paste3cols == 1 ~ as.character(latitude),
                             .default = as.character(gridref)),
         longitude = case_when(paste2cols == 1 ~ as.numeric(latitude),
                             paste3cols == 1 ~ as.numeric(extracol1),
                             .default = as.numeric(longitude)), 
         latitude = case_when(paste2cols == 1 ~ as.numeric(extracol1),
                             paste3cols == 1 ~ as.numeric(extracol2),
                             .default = as.numeric(latitude))) %>% 
  select(-c(extracol1, extracol2, paste2cols, paste3cols))

# For sites data from Rob, get relevant columns and rename them
sites.more.info <- sites.more.info %>%
  dplyr::select(-c("Site Name", "Gridreference", "Easting", "Northing","No. yrs surveyed", "First year surveyed", "Last year surveyed"))
 
names(sites.more.info) <- c("site", "length", "country", "no.sections",  "survey.type" )

# Rename columns in species 

species <- species %>% 
  rename(species.no = SPECIES, 
         common.name = COMMON_NAME,
         sci.name = SCI_NAME,
         strategy = STRATEGY,
         habitat = HABITAT)%>% 
  mutate(species.no = as.character(species.no))

#rename columns in records
records<- records %>%
  rename(site = SITE, 
        species.no = SPECIES,
        year = YEAR,
        month = MONTH, 
        day = DAY, 
        week.no = WEEKNO, 
        day.no = DAYNO, 
        count = COUNT) %>% 
  mutate(species.no = as.character(species.no))

# The warnings are because latitude and longitude are missing for some sites, so they get NAs from as.numeric()
```


```{r}
prisma <- add_prisma(step_name = "Renamed")
prisma
```


#### Merge site data from David and Rob
```{r}
# Some sites in David's list were not in site data from Rob
print("number of sites before merging operation")
nrow(sites)

sites <- merge(sites, sites.more.info, by = "site", all.x = TRUE)
print("number of sites after merging operation")
nrow(sites)
names(sites)
table(sites$survey.type)
```

#### Filter out zero counts to make processing quicker (note this removes info on surveys where no butterflies were seen).
```{r}
#The original dataset includes zeros where species were not observed at a site. The pivot_wider() function can reintroduce them in the site by species matrix, and meanwhile, we don't need to process them with the rest of the records. 

records <- filter(records, count !=0) #keep records where one or more butterflies of a species were seen at a site
filtered_data <- filter_ukbms("records")
# This updates the objects in the global environment with filtered versions
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Removed zero counts")
prisma
```


#### Filter out records that are moths, or do not identify to species level (low taxonomic resolution) or that denote that no butterflies were seen
```{r}
# Filter species dataset to only include butterflies
species <- species %>%
  filter(include ==1)
filtered_data <- filter_ukbms("species")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Removed moths, low-res ids")
prisma
```

#### Remove migrants and extinct species.
```{r}
# Two species were considered extinct before records started, and so any records now are eigher migrants or from butterfly farms, so can be removed with migrants. Also remove Large Copper Lycaena dispar (species.no 66), which is classified as a habitat specialist but is only present in a few sites and years following failed reintroduction attempts (not present in 2015-2019 data anyway) 
# https://butterfly-conservation.org/butterflies/large-tortoiseshell
# https://butterfly-conservation.org/butterflies/black-veined-white

# Filter species
print("Species strategies before filtering")
table(species$strategy)

species <- species %>% 
  filter(strategy == "Wider countryside sp"| strategy == "Habitat specialist",
         species.no != 66)

filtered_data <- filter_ukbms("species")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Removed migrants etc.")
prisma

print("Species strategies after filtering")
table(species$strategy)

print("Check that only ukbms surveys remain")
table(sites$survey.type)
```
#### Check for sites with inadequate locality info.
```{r}
# for inspection only, sites that have no co-ordinates or grid square reference
bad.sites <- filter(sites, is.na(longitude) == T | is.na(gridref) ==T | gridref == "Lurgan")

print("number of sites with inadequate locality info")
nrow(bad.sites)
```

# Remove sites in Ireland,  Channel Islands, Lundy, Scilly, Isle of Man from sites data.
```{r}
print("Sites in all countries before locality filtering")
table(sites$country)

# Filter sites
sites <- sites%>%
  filter(country != "Channel Isles" & country != "Isle of Man" & country != "Northern Ireland",
               site != 1791 & site != 1837)  # sites on Lundy and Scilly were identified manually

filtered_data <- filter_ukbms("sites")
list2env(filtered_data, envir = .GlobalEnv) 

prisma <- add_prisma(step_name = "Removed Ireland etc.")
prisma

print("Sites in remaining countries after locality filterint")
table(sites$country)
```

#### Add eastings, northings and National Grid References to site data
```{r}
# Check if all sites have latitude
any(is.na(sites$latitude))

# Get eastings and northings
pts <- sgo_points(sites, coords = c("longitude", "latitude"), epsg=4277) #this is the epsg for long and lat
bng.pts1 <- sgo_lonlat_bng(pts)

# Get national gridref 1 km scale 
points2 <- sgo_bng_ngr(bng.pts1, digits = 4)

#put coords and ngr into a dataframe
pts.df1 <- as.data.frame(bng.pts1)
pts.df1 <- pts.df1 %>%
  mutate(ngr.1km = points2$ngr,
         ngr.1km = str_replace_all(ngr.1km, fixed(" "), ""))  %>%  #get rid of white spaces
  select(x, y, ngr.1km, site)

sites <- merge(sites, pts.df1, by = "site")

filtered_data <- filter_ukbms("sites")
list2env(filtered_data, envir = .GlobalEnv)
 
prisma <- add_prisma(step_name = "Added NGR etc.")
prisma
```

## Plot Sites
```{r}
plot.points <- st_as_sf(sites, coords=c("x","y"), remove = FALSE, crs = 27700) 

basemap <-tm_shape(GB) +
  tm_borders()

pointsmap <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.05, col = "blue")

pointsmap2 <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.5, col = "blue")

print(pointsmap)
print(pointsmap2)
```

#### Filter records to 2015-2019 
```{r}
print("filter to 2015-2019")
records <- records %>% 
  filter(year %in% 2015:2019)

filtered_data <- filter_ukbms("records")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Kept 2015-2019")
prisma
```

#### Combine records for small and essex skipper (species.nos 119 and 120), including those where observer recorded it as either of the two (species.no 200). These species cannot be reliably distinguished on the wing.
```{r}
# Make a new row in species dataset for the combined species
new.row <- c ("1000", "Combined Skippers", "Thymelicus lineola-sylvestris", "Wider countryside sp", "Grassland", 1)

species <- species  %>%
  rbind(new.row)    %>%
  filter(species.no!= 119,
         species.no!= 120, 
         species.no!= 200)# in the original dataset, when it was identified as one
# of the two species, it was coded as 200. These are no longer present 
# after filtering above, so this is redundant 

# Recode species.no in records for the two skipper species in the records dataframe 
# to 1000 to match species dataframe.
records <- records %>% 
 mutate(species.no = case_match(species.no, c("119", "120", "200") ~ "1000", .default = species.no))

prisma <- add_prisma(step_name = "Combined 2 skippers")
prisma
```


#### Explore survey effort in terms of sampling spread across the survey period
```{r}
# Create a variable to group surveys by sampling period. Divide the prescribed survey period into 4 quarters. To have equal length quarters, the last week of March (week 0) is included in the first period and first week of October (week 40) in 4th period, although they are outside the survey period

# Create columns to identify survey events, site-year-month, and site-year combinations.
records <- records %>%
  mutate(survey.info = paste(site, year, month, day, week.no, sep = "_"),
         site.year.month = paste(site, year, month, sep = "_"),
         site.year = paste(site, year, sep = "_"))
# Check variation in sampling effort by week
table(records$week.no)
hist(records$week.no)

# Create sampling period variable
records <- mutate(records, 
                  sampling.period = case_match(week.no,
                    -7:-1 ~ "pre-april",
                    0:6   ~ "per1",
                    7:13  ~ "per2",
                    14:20 ~ "per3",
                    21:27 ~ "per4",
                    28:40 ~ "post-september"))

table(records$sampling.period)

# Get a dataframe with the number of surveys per period in each site in each year
surveys.by.period <- records %>%
  distinct(survey.info, .keep_all = TRUE) %>%
  group_by(site, year, sampling.period) %>%
  summarise(surveys.per.period = n()) %>%
  pivot_wider(names_from = sampling.period,
    values_from = surveys.per.period,
    values_fill = 0) %>%
  mutate(site.year = paste(site, year, sep = "_"), 
         #criterion for inclusion, being sampled in all 4 periods
         all.4 = per1 > 0 & per2 > 0 & per3 > 0 & per4 > 0) %>% 
  ungroup()


hist(surveys.by.period$per1, breaks = seq(-0.5, 27.5, 1))
hist(surveys.by.period$per2, breaks = seq(-0.5, 27.5, 1))
hist(surveys.by.period$per3, breaks = seq(-0.5, 27.5, 1))
hist(surveys.by.period$per4, breaks = seq(-0.5, 27.5, 1))
```

#### Filter to sites with two years sampled in all four sampling periods
```{r}
# Get number of years for each site that there were surveys in all four periods
sites.years.with.all.four  <- surveys.by.period %>% 
  filter(all.4 == TRUE) %>% 
  group_by(site) %>%
  summarise(years.with.all.four.periods = n())

# Check how many sites were well surveyed in 1, 2, 3, 4 or 5 years
table(sites.years.with.all.four$years.with.all.four.periods)


sites.years.with.all.four.in.two.years <- sites.years.with.all.four  %>%
  filter(years.with.all.four.periods >= 2)

# this merge adds info on number of years with all four periods and filters
# to only include years with two or more sites
sites <- merge(sites, sites.years.with.all.four.in.two.years, by = "site")

print("filter to sites with two years sampled in all four periods")
filtered_data <- filter_ukbms("sites")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Filtered all 4 periods")
tail(prisma)

print("number of sites")
table(sites$country)

```

#### Find sites with 8 surveys in at least two years
```{r}
# get criterion that all four years must be sampled in a dataframe to merge with
# the dataframe created below with number of surveys per year
periods.for.site.year <- select(surveys.by.period, site.year, all.4)

# Get the surveys per year for each site in each year 2015:2019
site.years.by.surveys <- records %>%
  distinct(survey.info, .keep_all = TRUE) %>%
  group_by(site, year) %>%
  summarise(surveys.per.year = n()) %>% #surveys per year
  ungroup() %>%
  mutate(site.year = paste(site, year, sep = "_")) %>%
  mutate(eightormore = surveys.per.year >= 8) %>% # logical criterion
  merge(periods.for.site.year, by = "site.year")


well.surveyed.sum <- site.years.by.surveys  %>% 
  filter(eightormore == TRUE & all.4 == TRUE) %>% #filter to well_sampled site-year combinations
    group_by(site) %>%
summarise(well.sampled.years = n())

table(well.surveyed.sum$well.sampled.years)
well.surveyed.sum <- filter(well.surveyed.sum, well.sampled.years >=2)
table(well.surveyed.sum$well.sampled.years)
```

#### Filter to only sites with 8 surveys in at least two years also satifying criteria above
```{r}
# Subset records to those from sites sampled in all four years
print("filter to sites with two years sampled in all four periods AND
      at least eight samples per year in those years")
sites <- filter(sites, site %in% well.surveyed.sum$site)


filtered_data <- filter_ukbms("sites")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(step_name = "Filtered >= 8 surveys Pa")
tail(prisma)

head(sites)
```

#### Inspect surveys per site
```{r}
surveys.by.site <- records %>%
  distinct(survey.info, .keep_all = TRUE) %>%
  group_by(site) %>%
    summarise(surveys = n()) 

print("number of species")
nrow(species)

hist(surveys.by.site$surveys, breaks = 100)
min(surveys.by.site$surveys)
```

#### Aggregate records across the five years
```{r}
# Sum records for each species in each site across years, getting total counted
# over 5 years for each species
records <-  records %>%
  group_by (site, species.no)  %>% 
summarise(total.count = sum(count))  %>% 
  ungroup()

prisma <- add_prisma(recs = records, step_name = "Aggregated records")

tail(prisma)
```

#### Get site by species count and presence/absence matrices
```{r}
# Get a site by species dataframe with counts of observations
site.by.obs.5.year.counts <- records %>%
  pivot_wider(names_from = species.no,
              values_from = total.count,
              values_fill = 0) %>% # zeros were filtered out at start, added back in here
  column_to_rownames(var = "site")

print("sites and species in matrix")
print("sites, species")
dim(site.by.obs.5.year.counts)

#make a presence/absence site by specie matrix

site.by.obs.5.year.presabs <- site.by.obs.5.year.counts
site.by.obs.5.year.presabs[site.by.obs.5.year.presabs[, ] > 0] <- 1
```


#### Calculate coverage and combine with richness and abundance data
```{r}
#Note, dataInfo() performs the first part of what iNEXT() does in seconds. the whole iNEXT() function would have to be left overnight for the whole dataset
#https://cran.r-project.org/web/packages/iNEXT/vignettes/Introduction.pdf

# get coverage values
check.coverage <- t(site.by.obs.5.year.counts)
coverage <- DataInfo(check.coverage,  datatype ="abundance")

# Inspect the distribution of coverage values
hist(coverage$SC)
hist(coverage$SC, ylim = c(0, 50))
hist(coverage$SC, xlim = c(0.95, 1), breaks = 1000)
quantile(coverage$SC, seq(from = 0, to = 1, by = 0.01))

# Get a dataframe with coverage values to merge into the sites dataframe
cov.merge <- coverage %>%
  dplyr::select(Assemblage, n, S.obs, SC) 
names(cov.merge) <- c("site", "total.butterflies", "richness", "coverage")
```

#### Add coverage, richnees and abundance data to sites and explore coverage
```{r}
sites <- merge(sites, cov.merge, by = "site")

scotland <- filter(sites, country == "Scotland")
wales <- filter(sites, country == "Wales")
england <- filter(sites, country == "England")


hist(scotland$coverage, xlim = c(0.98, 1), breaks = 1000)
hist(wales$coverage, xlim = c(0.98, 1), breaks = 1000)
hist(england$coverage, xlim = c(0.98, 1), breaks = 1000)

# Get some descriptive statistics for sites
sum3 <- sites%>%
  group_by(survey.type) %>%
  summarise(n = n(),
            mean.richness = mean(richness),
            mean.individuals = mean(total.butterflies),
            mean.coverage = mean(coverage)
      )
sum3
```


#### Explore the relationship between coverage and richness, for different ranges of coverage
```{r}
plot(richness~coverage, data = sites)

pdf(file = "rich+cov.pdf",  
    width = 4,
    height = 4) 
plot(richness~coverage, data = sites)
dev.off()

m2 <- lm(richness~coverage, data = sites)

check<- filter(sites, coverage >= 0.99)
m3 <- lm(richness~coverage, data = check)

check1<- filter(sites, coverage >= 0.995)
m4 <- lm(richness~coverage, data = check1)

check2<- filter(sites, coverage >= 0.999)
m5 <- lm(richness~coverage, data = check2)

summary(m2)
summary(m3)
summary(m4)
summary(m5)
```

#### Filter to sites with sufficient coverage and effort. 0.999 gives an expectation that one thousand individuals would have to be observed before a new species was observed.
```{r}
# Note also, the relationship between coverage and richness was not significant 
# for this range (m5 above)
sites <- sites %>% 
                filter(coverage >= 0.999)

filtered_data <- filter_ukbms("sites")
list2env(filtered_data, envir = .GlobalEnv)

prisma <- add_prisma(recs = records, step_name = "Removed low coverage")
tail(prisma)
```


#### redo site.by.species matrices after filtering for coverage
```{r}
# make species.no entries into format "species_1" etc
# this line is different, otherwise code should be kept identical to code above
records$species.no <- paste("species", records$species.no, sep = "_")

# Get a site by species dataframe with counts of observations
site.by.obs.5.year.counts <- records %>%
  pivot_wider(names_from = species.no,
              values_from = total.count,
              values_fill = 0) %>% # zeros were filtered out at start, added back in here
  column_to_rownames(var = "site")

print("sites and species in matrix")
print("sites, species")
dim(site.by.obs.5.year.counts)

#make a presence absence site by species matrix
site.by.obs.5.year.presabs <- site.by.obs.5.year.counts
site.by.obs.5.year.presabs[site.by.obs.5.year.presabs[, ] > 0] <- 1
```

#### Check all sites and species have occurrence data
```{r}
print("are there any species with no records")
any(colSums(site.by.obs.5.year.presabs)==0)

print("are there any sites with no records")
any(rowSums(site.by.obs.5.year.presabs)==0)

print("sites and species in matrix")
dim(site.by.obs.5.year.presabs)
```

#### Plot Sites
```{r }
plot.points <- st_as_sf(sites, coords=c("x","y"), remove = FALSE, crs = 27700)

print("sites")
nrow(plot.points)

basemap <-tm_shape(GB_simpl) +
  tm_borders()
pointsmap <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.05, col = "blue")

pointsmap2 <- basemap +
tm_shape(plot.points) +
  tm_symbols(size = 0.5, alpha = 0.5, col = "blue")

print(pointsmap)
print(pointsmap2)

```


#### Extract data on number of sites in 2015-2019 data before and after subsequent filtering
```{r}
prisma_short <- prisma[c(9, 12, 13), c(1,3) ]

prisma_short$Step <- c("All records", "Adequate effort", "Adequate coverage")

names(prisma_short) <- c("Records", "Sites Remaining")

prisma_short$`Sites Dropped` <- c(NA, abs(diff(prisma_short$`Sites Remaining`)))

```
#### modify sites dataframe for use later
```{r}
sites <- sites %>%
  mutate(site.no = site,
         site = paste("site", site.no, sep = "_")) %>%
   column_to_rownames("site") 
toc()
```


#### Save processed data and filtering summaries
```{r}
spatial_ukbms_obs_sites_spp <- list(site.by.obs.5.year.presabs, species, sites)
names(spatial_ukbms_obs_sites_spp) <- c("site.by.species", "species", "sites")

write_rds(spatial_ukbms_obs_sites_spp, file = here("./Data/Processed_Data/Spatial/spatial_ukbms_obs_sites_spp.rds"))

csv_path <- paste0(here("Output/Spatial/filtering",  "/"))
if(!dir.exists(csv_path)) dir.create(csv_path)

write_csv(prisma, file = paste0(csv_path, "/", "filtering_summary.csv"))
write_csv(prisma_short, file = paste0(csv_path, "/", "sites_filtering_summary.csv"))
```




